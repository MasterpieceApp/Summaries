{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 1: Вступление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки на повторение матана\n",
    "\n",
    "1. [Linear Algebra](http://cs229.stanford.edu/section/cs229-linalg.pdf)\n",
    "2. [Probability Theory](http://cs229.stanford.edu/section/cs229-prob.pdf)\n",
    "3. [SGD](http://cs231n.github.io/optimization-1/)\n",
    "4. [Convex Optimization](http://cs229.stanford.edu/section/cs229-cvxopt.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конспект\n",
    "\n",
    "[Здесь](http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-notes1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 2: Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезно почитать\n",
    "\n",
    "* [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "* [Mikolov \"Distributed Representations of Words and Phrases and their Compositionality\"](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "* [Mikolov \"Efficient Estimation of Word Representations in Vector Space\"](https://arxiv.org/pdf/1301.3781.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача:__ $$ p(context \\: | \\: w_t) $$\n",
    "\n",
    "__Функция стоимости:__ $$ J = 1 - p(w_{-t} \\:|\\: w_t) $$, где $_{-t}$ значит _\"все слова контекста, кроме $t$\"_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два алгоритма:\n",
    "\n",
    "1. __Skip-grams (SG)__ - _будет разобран далее_.\n",
    "   \n",
    "   Предсказывать контекст по слову (без разницы на позицию).\n",
    "<br><br>\n",
    "\n",
    "2. Continuous Bag of Words (CBOW). \n",
    "    \n",
    "    Предсказывать слово из BOW-контекста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Два (средне эффективных) метода обучения:\n",
    "\n",
    "1. Иерархический софтмакс.\n",
    "2. Negative sampling. \n",
    "\n",
    "__Naive softmax__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбор \n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^T \\sum_{-m \\le j \\le m, j \\ne 0} \\log p(w_{t+j} \\:|\\: w_t)$$\n",
    "\n",
    "$$ p(o \\:|\\: c) = \\frac{\\exp(u_o^Tv_c)}{\\sum_{w=1}^V \\exp(u_w^Tv_c)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", где $ \\theta = \\begin{bmatrix}\n",
    "           v_{aardvark} \\\\\n",
    "           v_{a} \\\\\n",
    "           \\vdots \\\\\n",
    "           v_{zebra} \\\\\n",
    "           u_{aardvark} \\\\\n",
    "           u_{a} \\\\\n",
    "           \\vdots \\\\\n",
    "           u_{zebra}\n",
    "         \\end{bmatrix} \\in \\mathbb{R}^{2dV} $, $c$ - center indices, $o$ - outside indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы заработал градиентный спуск, надо взять две производные по $v$ и по $u$, и спускаться с шагом обучения. И раз $J(\\theta)$ у нас задан, приступим:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial}{\\partial v_c} \\log \\frac{\\exp(u_o^Tv_c)}{\\sum_{w=1}^V \\exp(u_w^Tv_c)} =$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{\\partial}{\\partial v_c} \\log \\exp(u_o^Tv_c) - \\frac{\\partial}{\\partial v_c} \\log \\sum_{w=1}^V \\exp(u_w^Tv_c) =$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{\\partial}{\\partial v_c} u_o^Tv_c - \\Big( \\frac{1}{\\sum_{w=1}^V \\exp(u_w^Tv_c) } \\Big) \\frac{\\partial}{\\partial v_c} \\sum_{x=1}^V \\exp (u_x^Tv_c) =$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = u_o - \\Big( \\frac{1}{\\sum_{w=1}^V \\exp(u_w^Tv_c) } \\Big) \\sum_{x=1}^V \\frac{\\partial}{\\partial v_c} \\exp (u_x^Tv_c) =$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = u_o - \\Big( \\frac{1}{\\sum_{w=1}^V \\exp(u_w^Tv_c) } \\Big) \\sum_{x=1}^V \\exp(u_x^Tv_c) \\frac{\\partial}{\\partial v_c} u_x^Tv_c = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = u_o - \\Big( \\frac{1}{\\sum_{w=1}^V \\exp(u_w^Tv_c) } \\Big) \\sum_{x=1}^V \\exp(u_x^Tv_c) \\: u_x = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = u_o - \\sum_{x=1}^V \\frac{\\exp(u_x^Tv_c)}{\\sum_{w=1}^V \\exp(u_w^Tv_c) } =$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = u_o - \\sum_{x=1}^V p(x \\:|\\: c) \\: u_x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили разницу между observed вектором и векторами всех остальных слов, взвешенными правдоподобностью возникновения в контексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная по $u$ - домашка :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбор статьи\n",
    "\n",
    "\n",
    "* [Arora __\"A Simple but Tough-to-Beat Baseline for Sentence Embeddings\"__](https://openreview.net/pdf?id=SyK00v5xx)\n",
    "\n",
    "__Старый подход в BOW:__ \n",
    "\n",
    "`v(\"one two three\") = 1/3\\*(v(\"one\") + v(\"two\") + v(\"three\"))`\n",
    "\n",
    "__Новый подход:__\n",
    "\n",
    "* __Шаг 1.__ Для каждого предложения $s$ в тексте $S$:\n",
    "\n",
    "$$ v_s \\leftarrow \\frac{1}{|s|}\\sum_{w \\in s} \\frac{a}{a+p(w)}v_w $$\n",
    "\n",
    "Здесь $a$ выполняет роль регуляризации. В целом у шага 1 интуиция во взвешивании слов по их частоте.\n",
    "\n",
    "* __Шаг 2.__ Вычисли первую PCA-компоненту $u$ для каждого $ \\{ v_s \\::\\: s \\in S \\} $. Далее для каждого предложения $s$ в тексте $S$:\n",
    "\n",
    "$$ v_s \\leftarrow v_s - uu^Tv_s $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
